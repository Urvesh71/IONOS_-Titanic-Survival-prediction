{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12576362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U imbalanced-learn\n",
    "# !pip install lightgbm\n",
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb53bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EDA Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa4e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Preprocessing and Machine learning libraries\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8a9c8",
   "metadata": {},
   "source": [
    "## 1. Dataset loading and Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Training dataset\n",
    "train_dataset = \"C:/Urvesh Koshti/1_Documents/Interview tasks/train.csv\"\n",
    "titanic_train_df = pd.read_csv(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25489685",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df.shape  # Check the shape of the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f3c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Testing dataset\n",
    "test_dataset = \"C:/Urvesh Koshti/1_Documents/Interview tasks/test.csv\"\n",
    "titanic_test_df = pd.read_csv(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03796c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df.shape  # Check the shape of the Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66bc0ad",
   "metadata": {},
   "source": [
    "#### Training Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeceac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df = titanic_train_df.drop(\n",
    "    ['PassengerId', 'Ticket'], axis=1\n",
    ")  # Dropping the PassengerID and Ticket column as they seem unnecessary for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3042be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values from each column of the Training dataset\n",
    "titanic_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1912b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of people who survived and did not survive\n",
    "survived_count = titanic_train_df['Survived'].value_counts()[1]\n",
    "not_survived_count = titanic_train_df['Survived'].value_counts()[0]\n",
    "\n",
    "# Calculate labels and percentages\n",
    "labels = ['Survived', 'Not Survived']\n",
    "values = [survived_count, not_survived_count]\n",
    "percentages = [f\"{val:.1f}%\" for val in [(v / sum(values)) * 100 for v in values]]\n",
    "\n",
    "# Create a pie chart with Plotly\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, text=percentages, textinfo='percent',\n",
    "                             hole=.3, marker={'colors': ['lightblue', 'lightsalmon']})])\n",
    "fig.update_layout(title='Distribution of Survivors on the Titanic')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa65fd",
   "metadata": {},
   "source": [
    "Figure shows only 38.4% people could survive from the Titanic Ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1859f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.violin(titanic_train_df, x='Sex', y='Age', title='Violin Plot of Age by Sex of the Training Dataset', box=True, points=\"all\")\n",
    "\n",
    "# Customize the layout if needed\n",
    "fig.update_layout(\n",
    "    xaxis_title='Sex',\n",
    "    yaxis_title='Age',\n",
    "    legend_title='Sex'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0424951",
   "metadata": {},
   "source": [
    "From the above figure, it seems that there were more Male people rather than Female people.In total, there were more people with the age between 20 and 35 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(titanic_train_df, x='Pclass', y='Age', title='Box Plot of Age by Sex of the Training Dataset')\n",
    "\n",
    "# Customize the layout if needed\n",
    "fig.update_layout(\n",
    "    xaxis_title='Pclass',\n",
    "    yaxis_title='Age',\n",
    "    legend_title='Sex'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20522b",
   "metadata": {},
   "source": [
    "From the above Figure, it seems that people with the age after 30 years are likely to bought the First class ticket where the young people, people with the age around 20 years are likely to bought third class ticket as they do not want to spend much money on the ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb7fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age_by_class_train = titanic_train_df.groupby(by = \"Pclass\").mean(\"Age\").Age\n",
    "print(mean_age_by_class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9064db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1,4):\n",
    "    age = pd.DataFrame(titanic_train_df[titanic_train_df.Pclass == j].Age).fillna(mean_age_by_class_train[j])\n",
    "    titanic_train_df.update(age)  # Filling missing values based on the mean value of the respective Ticket Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df.Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84b516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df.Cabin  = titanic_train_df.Cabin.fillna(\"Undefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40f376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent = titanic_train_df.Embarked.mode().values[0]\n",
    "titanic_train_df.Embarked = titanic_train_df.Embarked.fillna(most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c4c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3a34c",
   "metadata": {},
   "source": [
    "#### Testing Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fff991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values from each column of the Test dataset\n",
    "titanic_test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1312be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Sex' and 'Age' are the columns in your dataset\n",
    "fig = px.violin(titanic_test_df, x='Sex', y='Age', title='Violin Plot of Age by Sex of the Testing Dataset', box=True, points=\"all\")\n",
    "\n",
    "# Customize the layout if needed\n",
    "fig.update_layout(\n",
    "    xaxis_title='Sex',\n",
    "    yaxis_title='Age',\n",
    "    legend_title='Sex'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5cdfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(titanic_test_df, x='Pclass', y='Age', title='Box Plot of Age by PClass of the Testing Dataset')\n",
    "\n",
    "# Customize the layout if needed\n",
    "fig.update_layout(\n",
    "    xaxis_title='Pclass',\n",
    "    yaxis_title='Age',\n",
    "    legend_title='Sex'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de43497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_age_by_class_test = titanic_test_df.groupby(by = \"Pclass\").mean(\"Age\").Age\n",
    "print(mean_age_by_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89064d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(1,4):\n",
    "    age = pd.DataFrame(titanic_test_df[titanic_test_df.Pclass == j].Age).fillna(mean_age_by_class_test[j])\n",
    "    titanic_test_df.update(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df.Cabin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd611d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df.Cabin = titanic_test_df.Cabin.fillna(\"Undefined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6ef5be",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) on the Training Dataset (train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c60bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df[titanic_train_df['Survived'] == 1], x='Age', title='Age Distribution of Survived Individuals',\n",
    "                   labels={'Age': 'Age'},\n",
    "                   nbins=30,  # Adjust the number of bins for better granularity\n",
    "                   color_discrete_sequence=['green'],  # Color for survived individuals\n",
    "                   marginal='rug'  # Display individual data points on the sides\n",
    "                   )\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Age of Survived people',\n",
    "    yaxis_title='Count of Survived people',\n",
    "    legend_title='Survived',  # Legend title\n",
    "    legend=dict(traceorder='normal'),  # Display the legend\n",
    "    # template='plotly_dark',  # Use a dark template for a more aesthetic look\n",
    "    bargap=0.1\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ac59f",
   "metadata": {},
   "source": [
    "Above figure shows that there is less likely of having a chance of Survival of the people above 40 years of age. However, figure depicts that there are more number of survivals whose age lies between 20 and 40. One of the reason could be: there are more young people compared to Old people intotal in the Titanic Ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1cd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df, x='Sex', barmode='group',\n",
    "                   color='Survived', labels={'Survived': 'Survival Status'},\n",
    "                  color_discrete_sequence = px.colors.qualitative.Pastel)\n",
    "\n",
    "fig.update_layout(title='Titanic Survivors by Sex',\n",
    "                  xaxis_title='Sex',\n",
    "                  yaxis_title='Count',\n",
    "                 bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055efa2",
   "metadata": {},
   "source": [
    "Above figure shows that there more female survivers compared to male. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387154b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_women = titanic_train_df.loc[titanic_train_df.Sex == 'female'][\"Survived\"]\n",
    "survival_rate_women = sum(df_women)/len(df_women) * 100\n",
    "\n",
    "print(f\"Percentage of females who survived: {survival_rate_women:.2f}%\")\n",
    "\n",
    "df_men = titanic_train_df.loc[titanic_train_df.Sex == 'male'][\"Survived\"]\n",
    "survival_rate_men = sum(df_men)/len(df_men) * 100\n",
    "\n",
    "print(f\"Percentage of males who survived: {survival_rate_men:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df[titanic_train_df['Survived'] == 1], x='Pclass', barmode='group',\n",
    "                   color='Survived', labels={'Survived': 'Survival Status according to Pclass'},\n",
    "                  color_discrete_sequence = px.colors.qualitative.Pastel)\n",
    "\n",
    "fig.update_layout(title='Titanic Survivors by Pclass',\n",
    "                  xaxis_title='PClass',\n",
    "                  yaxis_title='Count',\n",
    "                 bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e462c",
   "metadata": {},
   "source": [
    "Above figure shows that highest number of people survived who had 1st Class Ticket. On the other side, people having 2nd class tickets had a highest possibility of non survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df[titanic_train_df['Survived'] == 1], x='SibSp', barmode='group',\n",
    "                   color='Survived', labels={'Survived': 'Survival Status according to Siblings and Spouse'},\n",
    "                  color_discrete_sequence = px.colors.qualitative.Pastel)\n",
    "\n",
    "fig.update_layout(title='Titanic Survivors by Siblings/Spouses',\n",
    "                  xaxis_title='Number of Siblings and Spouse',\n",
    "                  yaxis_title='Count of the Survivors',\n",
    "                 bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8edd716",
   "metadata": {},
   "source": [
    "Above figure shows the scenario of survival possibility of the people having siblings or spouse. Figure depicts that people having 0 Siblings or Spouse along with them have a high possibility of Survival. This possibility seems going down as the people having siblings or spouse increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac20476",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df[titanic_train_df['Survived'] == 1], x='Parch', barmode='group',\n",
    "                   color='Survived', labels={'Survived': 'Survival Status'},\n",
    "                  color_discrete_sequence = px.colors.qualitative.Pastel)\n",
    "\n",
    "fig.update_layout(title='Titanic Survivors by Number of Parents or Children aboard on the Titanic',\n",
    "                  xaxis_title='Number of Parents and children',\n",
    "                  yaxis_title='Count of the Survivors',\n",
    "                 bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc95455",
   "metadata": {},
   "source": [
    "In above figure as well, the same scenario can be seen as it is in case of number of siblings or spouse aboard in the Ship. People having no Parents or Children along with them had highest possibility of surviving. However, survival possibility is getting low as number of children or parents increases. People having in total 4 (childred + parents) had a 0% possibilty of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fd84e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.box(titanic_train_df, x='Survived', y='Fare', title='Fare Distribution by Survival Status based on the Fare',\n",
    "             labels={'Survived': 'Survival'},\n",
    "             color='Survived',  # Color by survival status for better visualization\n",
    "             color_discrete_map={0: 'red', 1: 'green'})\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(\n",
    "    xaxis_title='Survival Status',\n",
    "    yaxis_title='Fare',\n",
    "    legend_title='Survived',\n",
    "    # template='plotly_dark'  # Use a dark template for a more aesthetic look\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea4972",
   "metadata": {},
   "source": [
    "From the above figure, it seems that when the fare cost goes up, there is only a small increase in the chance of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df[titanic_train_df['Survived'] == 1], x='Embarked', barmode='group',\n",
    "                   color='Survived', labels={'Survived': 'Survival Status according to Pclass'},\n",
    "                  color_discrete_sequence = px.colors.qualitative.Pastel)\n",
    "\n",
    "fig.update_layout(title='Titanic Survivors by Port of Embarkation',\n",
    "                  xaxis_title='Embarked',\n",
    "                  yaxis_title='Count of Survived passengers',\n",
    "                 bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8d01b",
   "metadata": {},
   "source": [
    "C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "\n",
    "From the above figure, it can be seen that people who boarded the Titanic ship from Southampton, England, had the highest chance of surviving. Those who boarded from Cherbourg, France, and Queenstown (Cobh), Ireland, had lower chances of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the dataframe's 'Name' column, extract the Prefix of the Name and make it as a New column \n",
    "titanic_train_df['title_name'] = titanic_train_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "titanic_test_df['title_name'] = titanic_test_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc12fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9472c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df['title_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96598dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df['title_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c87051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_titles(title):\n",
    "    if title in ['Mr', 'Mrs', 'Miss', 'Master']:\n",
    "        return title\n",
    "    else:\n",
    "        return 'Other titles'\n",
    "\n",
    "# Applying the function to df_train title_name column\n",
    "titanic_train_df['title_name'] = titanic_train_df['title_name'].apply(categorize_titles)\n",
    "\n",
    "titanic_test_df['title_name'] = titanic_test_df['title_name'].apply(categorize_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57336a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the 'Name' column as full names aren't needed for building the model\n",
    "titanic_train_df = titanic_train_df.drop('Name', axis=1)\n",
    "\n",
    "titanic_test_df = titanic_test_df.drop('Name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfb1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding two columns 'SibSp' and 'Parch' to make the one column which represets one family Size that inclues the children, spouse, parents and the person itself. \n",
    "titanic_train_df['family_size'] = titanic_train_df['SibSp'] + titanic_train_df['Parch']\n",
    "\n",
    "titanic_test_df['family_size'] = titanic_test_df['SibSp'] + titanic_test_df['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181fbd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df[titanic_train_df['Survived'] == 1], x='family_size', y='Survived',\n",
    "                   title='Survival Rate by Family Size',\n",
    "                   labels={'Survived': 'Survival Rate'},\n",
    "                   template='plotly_dark', text_auto=True,\n",
    "                   color_discrete_sequence=['#10c2de']\n",
    "                  )\n",
    "\n",
    "fig.update_layout(title='Titanic Survivors by the size of the family (Children + Spouse + Parents + Person itself)',\n",
    "                  xaxis_title='Family Size',\n",
    "                  yaxis_title='Count of Survived passengers',\n",
    "                 bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699f714",
   "metadata": {},
   "source": [
    "- Smaller families, consisting of three members or fewer, were more likely to survive, while those with four or more members had a lower probability of making it through the incident.\n",
    "\n",
    "- The data suggests that, overall, smaller families were safer during the event. Moreover, individuals traveling alone had the highest chances of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec119d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(titanic_train_df[titanic_train_df['Survived'] == 1], x='title_name', y='Survived',\n",
    "                   title='Survival Rate by a Prefix of the person name',\n",
    "                   labels={'Survived': 'Survival Rate'},\n",
    "                   template='plotly_dark', text_auto=True,\n",
    "                   color_discrete_sequence=['#10c2de']\n",
    "                  )\n",
    "\n",
    "fig.update_layout(xaxis_title='Title (Prefix) of the passenger',\n",
    "                  yaxis_title='Count of Survived passengers',\n",
    "                 bargap=0.1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31792bba",
   "metadata": {},
   "source": [
    "The above figure shows that the women with titles \"Miss\" and \"Mrs.\" survived the most. This shows that women were the top priority for survival during the incident compared to Men people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0217aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67858fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ac836",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb979c56",
   "metadata": {},
   "source": [
    "- Training Dataset does not have any missing values now since they are already handeled at the starting part of the work.\n",
    "\n",
    "- Testing Dataset has one missing value in the column called 'Fare' which is handeled as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mean value of all values available in the 'Fare' column\n",
    "titanic_test_df['Fare'].fillna(titanic_test_df['Fare'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d2985",
   "metadata": {},
   "source": [
    "- In the Training Dataset and Testing Dataset, There are three columns 'Sex', 'title_name', 'Embarked' that has Categorical values. To consider this columns in Machine Learning Model, there is a need to represent these Categorical values in a numerical form. \n",
    "\n",
    "- Therefore, to convert the categorical values into Numerical values, a concept called 'One Hot Encoding' is applied as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52d6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the get_dummies() function for one-hot encoding\n",
    "titanic_train_df_encoded = pd.get_dummies(titanic_train_df, columns=['Sex', 'title_name', 'Embarked'])\n",
    "\n",
    "# Display the DataFrame with one-hot encoding\n",
    "titanic_train_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6630f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_df_encoded = titanic_train_df_encoded.drop(\n",
    "    ['Cabin'], axis=1\n",
    ")  # Removing further unnecessary column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d287dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the get_dummies() function for one-hot encoding\n",
    "titanic_test_df_encoded = pd.get_dummies(titanic_test_df, columns=['Sex', 'title_name', 'Embarked'])\n",
    "\n",
    "# Display the DataFrame with one-hot encoding\n",
    "titanic_test_df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df_encoded = titanic_test_df_encoded.drop(\n",
    "    ['Cabin'], axis=1\n",
    ")  # Removing further unnecessary column from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8f1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the x Featues and y Targets\n",
    "X = titanic_train_df_encoded.drop('Survived',axis=1)\n",
    "y = titanic_train_df_encoded['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c850f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f88b87",
   "metadata": {},
   "source": [
    "- In the Training dataset, a Data Imbalance is seen. Data imbalance refers to a situation in a dataset where the distribution of instances across different classes is not equal or balanced. In a classification problem, where the goal is to categorize instances into two or more classes, data imbalance occurs when one class has significantly more or fewer instances than another class.\n",
    "\n",
    "- In order to overcome the Data Imbalance, Resampling technique can be implemented. Resampling means either oversampling the minority class or undersampling the majority class to create a more balanced dataset. This can be done by Creating synthetic instances for the minority class using techniques like SMOTE (Synthetic Minority Over-sampling Technique) as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to oversample the minority class in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display the count of each class before and after resampling\n",
    "print(\"Class distribution before Resampling:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nClass distribution after Resampling:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d180c",
   "metadata": {},
   "source": [
    "Now in the Training dataset, there are equal scenario of Survived as '0' and Survived as '1'. The dataset is balanced and hence, it will prevent the Machine Learning (ML) model being a Bias towards the Majority samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522f7166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the Standardization on the Dataset to make features have similar scales and follow a standard normal distribution. \n",
    "\n",
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'family_size']\n",
    "\n",
    "# Creating a RobustScaler instance\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fitting the RobustScaler on the training data\n",
    "scaler.fit(X_train[numerical_features])\n",
    "\n",
    "# Transforming (scaling) the continuous features in the training and testing data\n",
    "X_train_cont_scaled = scaler.transform(X_train[numerical_features])\n",
    "X_test_cont_scaled = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "# Replacing the scaled continuous features in the original data\n",
    "X_train[numerical_features] = X_train_cont_scaled\n",
    "X_test[numerical_features] = X_test_cont_scaled\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fe379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation values with the target variable\n",
    "correlation_with_target = titanic_train_df_encoded.corr()['Survived'].drop('Survived')\n",
    "\n",
    "# Create a grouped bar chart for visualization\n",
    "fig = px.bar(x=correlation_with_target.index, y=correlation_with_target.values,\n",
    "             labels={'x': 'Features', 'y': 'Correlation with Target'},\n",
    "             title='Correlation with Target for each Feature',\n",
    "             color=correlation_with_target.values > 0,  # Color by positive/negative correlation\n",
    "             color_discrete_sequence=['red', 'green'],  # Red for negative, green for positive\n",
    "             )\n",
    "\n",
    "# Customize the layout\n",
    "fig.update_layout(template='plotly_dark')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55eabee",
   "metadata": {},
   "source": [
    "From above plot, it can be seen that Features 'Age', 'SibSp', 'family_size' and 'title_name_Other_titles' do not contribute much and have very less correlation with the target variable. Hence, these features can be removed from the datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483280ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop less correlated features from the Dataset\n",
    "X_train_mostrelated_features = X_train.drop(['Age', 'SibSp', 'family_size', 'title_name_Other titles'], axis=1)\n",
    "X_test_mostrelated_features = X_test.drop(['Age', 'SibSp', 'family_size', 'title_name_Other titles'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7bd1b",
   "metadata": {},
   "source": [
    "## Implementing a Machine Learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb926c",
   "metadata": {},
   "source": [
    "Before making prediction, it is important to check which ML model will make the better prediction. Therefore, below are different classification Models which can be evaluated on the Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7efe0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of classifiers to evaluate\n",
    "classifiers = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42, max_iter= 1500, n_jobs=-1)),\n",
    "    (\"KNN\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),\n",
    "    (\"Gaussian Naive Bayes\", GaussianNB()),\n",
    "    (\"SVC\", SVC(random_state=42, probability=True)),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42, n_jobs =-1)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier(random_state=42)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
    "    (\"LightGBM\", lgb.LGBMClassifier(random_state=42, verbose=-1)),\n",
    "    (\"XGBoost\", xgb.XGBClassifier(random_state=42, n_jobs =-1))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f66e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists for classifier names, mean_test_f1_scores, cross_val_errors, mean_test_accuracies, and results.\n",
    "results = []\n",
    "mean_test_f1_scores = []\n",
    "mean_test_accuracies = []\n",
    "cross_val_errors = []\n",
    "classifier_names = []\n",
    "\n",
    "# Applying cross-validation helps us thoroughly test machine learning models. \n",
    "# It checks their performance across various datasets, ensuring a strong evaluation. \n",
    "# This method involves testing features on different data parts, guaranteeing they work well across different situations. \n",
    "\n",
    "for model_name, model in classifiers:\n",
    "    \n",
    "    # 5-fold Stratified Cross-Validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation with train and test scores\n",
    "    cv_results = cross_validate(model, X_train_mostrelated_features, y_train, cv=cv, scoring=['f1', 'accuracy'], n_jobs=-1, return_train_score=True)\n",
    "\n",
    "    # Calculate cross-validation error\n",
    "    cross_val_error = 1 - np.mean(cv_results['test_accuracy'])\n",
    "\n",
    "    # Append results to the list\n",
    "    results.append({\n",
    "        \"Model Name\": model_name,\n",
    "        \"Mean Train F1 Score\": np.mean(cv_results['train_f1']),\n",
    "        \"Mean Test F1 Score\": np.mean(cv_results['test_f1']),\n",
    "        \"Mean Test Accuracy\": np.mean(cv_results['test_accuracy']),\n",
    "        \"Cross-Validation Error\": cross_val_error\n",
    "    })\n",
    "    \n",
    "    mean_test_f1_scores.append(np.mean(cv_results['test_f1']))\n",
    "    mean_test_accuracies.append(np.mean(cv_results['test_accuracy']))\n",
    "    cross_val_errors.append(cross_val_error)\n",
    "    classifier_names.append(model_name)\n",
    "\n",
    "# Create a DataFrame from the results list\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcee07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = results_df['Model Name'].tolist()\n",
    "mean_test_accuracy = results_df['Mean Test Accuracy'].tolist()\n",
    "cross_validation_error = results_df['Cross-Validation Error'].tolist()\n",
    "\n",
    "# Creating the stacked bar chart\n",
    "trace1 = go.Bar(\n",
    "    x=model_names,\n",
    "    y=mean_test_accuracy,\n",
    "    name='Mean Test Accuracy',\n",
    "    marker_color='royalblue'\n",
    ")\n",
    "\n",
    "trace2 = go.Bar(\n",
    "    x=model_names,\n",
    "    y=cross_validation_error,\n",
    "    name='Cross-Validation Error',\n",
    "    marker_color='coral'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[trace1, trace2])\n",
    "\n",
    "# Setting the layout of the chart\n",
    "fig.update_layout(\n",
    "    barmode='stack',  # Stack the bars on top of each other\n",
    "    xaxis_title='Model Name',\n",
    "    yaxis_title='Score',\n",
    "    title='Mean Test Accuracy and Cross-Validation Error',\n",
    "    # xaxis_tick_angle=45  # Rotate x-axis labels for better readability\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db4d8d",
   "metadata": {},
   "source": [
    "From above figure, it can be seen that among all classifiers, LightGBM classifier exhibits the highest Accuracy and lowest Cross Validation Error. Therefore, LightGBM seems to be the Model for the further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164d23b3",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning with the Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf49253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LightGBM classifier\n",
    "lgb_classifier = lgb.LGBMClassifier(objective='binary', metric='binary_logloss', random_state=42)\n",
    "\n",
    "# Define the hyperparameters to tune and their possible values\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 100],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgb_classifier, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train_mostrelated_features, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_lgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_lgb_model.predict(X_test_mostrelated_features)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on Test Set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f4045",
   "metadata": {},
   "source": [
    "#### Prediction on the Testing Dataset (test.csv) using LightGBM as a Machine Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b0b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ebb23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a New dataframe for saving a prediction result\n",
    "result_dataframe = pd.DataFrame(\n",
    "    {\n",
    "     'PassengerId': titanic_test_df_encoded.PassengerId,\n",
    "     'Survived': \"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d72859",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df_encoded = titanic_test_df_encoded.drop(\n",
    "    ['PassengerId', 'Ticket', 'Age', \n",
    "     'SibSp', 'family_size', 'title_name_Other titles'], axis=1\n",
    ")  # Removing unnecessary Columns from the Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67695de",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test_df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ebd4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_lgb_model.predict(\n",
    "    titanic_test_df_encoded\n",
    ")  # Prediction on the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c91e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe['Survived'] = predictions  # Adding prediction values to the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3345ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe.to_csv(\n",
    "    'result_dataframe_test_dataset.csv', index=False\n",
    ")  # Saving the Predicted result in a CSV file\n",
    "print(\"Results are successfully saved in csv file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702793c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
